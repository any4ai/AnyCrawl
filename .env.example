ANYCRAWL_NAME=AnyCrawl
ANYCRAWL_DOMAIN=http://localhost:8080
ANYCRAWL_API_PORT=8080

ANYCRAWL_HEADLESS=true
ANYCRAWL_PROXY_URL=
ANYCRAWL_PROXY_STEALTH_URL=
ANYCRAWL_PROXY_CONFIG=
ANYCRAWL_KEEPALIVE=true
ANYCRAWL_AVAILABLE_ENGINES=playwright,cheerio,puppeteer

ANYCRAWL_IGNORE_SSL_ERROR=true

ANYCRAWL_API_AUTH_ENABLED=false
ANYCRAWL_API_CREDITS_ENABLED=false

ANYCRAWL_API_DB_TYPE=sqlite
ANYCRAWL_API_DB_CONNECTION=${PWD}/database.db
ANYCRAWL_REDIS_URL=redis://redis:6379

# Do not configure unless you know what you're doing.
ANYCRAWL_MAX_CONCURRENCY=50
ANYCRAWL_MIN_CONCURRENCY=50

# if not configured, will use the browser us 
ANYCRAWL_USER_AGENT=AnyCrawl/0.1 (+https://github.com/any4ai/AnyCrawl)

ANYCRAWL_NAME_KEY_VALUE_STORE=AnyCrawl

# Storage backend: set to "s3" to enable S3 storage (files/screenshots) and page cache.
# Any other value (or empty) uses local/no-op storage depending on feature.
ANYCRAWL_STORAGE=

ANYCRAWL_S3_BUCKET=
ANYCRAWL_S3_REGION=us-east-1
ANYCRAWL_S3_ENDPOINT=
ANYCRAWL_S3_ACCESS_KEY=
ANYCRAWL_S3_SECRET_ACCESS_KEY=

# Cache (map cache works with DB; page cache requires ANYCRAWL_STORAGE=s3)
# Set to "false" to disable all caching.
ANYCRAWL_CACHE_ENABLED=true
# Default page cache max age (ms). Default: 2 days.
ANYCRAWL_CACHE_DEFAULT_MAX_AGE=172800000
# Sitemap/map cache max age (ms). Default: 7 days.
ANYCRAWL_CACHE_SITEMAP_MAX_AGE=604800000

# Optional: use a separate bucket/prefix for cache objects (defaults to ANYCRAWL_S3_BUCKET).
# - Only affects page cache objects stored in S3 (map cache is stored in DB).
# - Leave empty to use ANYCRAWL_S3_BUCKET.
# - If set, ensure the bucket is reachable with the same S3 endpoint/region/credentials.
ANYCRAWL_S3_CACHE_BUCKET=
# Folder prefix inside the cache bucket. Default: "cache/"
ANYCRAWL_S3_CACHE_PREFIX=cache/


# AI feature
# ANYCRAWL_AI_CONFIG_PATH=
# if set ANYCRAWL_AI_CONFIG_PATH, the coming ai env will be disabled.
# AI for extracting
# format: openai/gpt-40
# Connect the provider name and the model name with a "/", such as openai:gpt-4o-mini, openrouter:openai/gpt-4o-mini, custom/glm-4.5
DEFAULT_LLM_MODEL=
DEFAULT_EXTRACT_MODEL=
DEFAULT_EMBEDDING_MODEL=

# Support configuring many providers, and decide by model name.
# Provide your OpenAI API key here to enable AI features
# OPENAI_API_KEY=

# OpenRouter
# OPENROUTER_API_KEY=

# OpenAI-compatible API, the provider name is: "custom"
# CUSTOM_BASE_URL=https://example.com/v1
# CUSTOM_API_KEY=

# OCR (OpenAI-compatible Vision/OCR provider)
# Example:
# ANYCRAWL_VL_REC_SERVER_URL=https://api.siliconflow.cn/v1
# ANYCRAWL_VL_REC_API_KEY=your-key
ANYCRAWL_VL_REC_SERVER_URL=
ANYCRAWL_VL_REC_API_KEY=
ANYCRAWL_VL_REC_MODEL=PaddlePaddle/PaddleOCR-VL-1.5
ANYCRAWL_VL_REC_PROVIDER_NAME=vlRec
ANYCRAWL_VL_REC_MAX_OUTPUT_TOKENS=2048
ANYCRAWL_VL_REC_TIMEOUT_MS=30000
ANYCRAWL_VL_REC_MIN_PIXELS=112896
ANYCRAWL_VL_REC_MAX_PIXELS=1003520

ANYCRAWL_EXTRACT_JSON_CREDITS=5
ANYCRAWL_SUMMARY_CREDITS=0
ANYCRAWL_PROXY_STEALTH_CREDITS=5
ANYCRAWL_TEMPLATE_EXECUTION_TIMEOUT=600_000
ANYCRAWL_REQUEST_HANDLER_TIMEOUT_SECS=600_000
ANYCRAWL_SEARCH_DEFAULT_ENGINE=ac-engine
ANYCRAWL_SEARCH_ENABLED_ENGINES=ac-engine,searxng
ANYCRAWL_AC_ENGINE_URL=
ANYCRAWL_SEARXNG_URL=https://searxng-q4cwo8wwoswkswcwk444occs.nicelab.top/


ANYCRAWL_TEMPLATE_CACHE_TTL_MS=0

ANYCRAWL_SCHEDULER_ENABLED=true
ANYCRAWL_SCHEDULER_SYNC_INTERVAL_MS=10000  # Polling interval to detect new tasks (default: 10 seconds)

# Scheduled Tasks Limits (disabled by default for open-source)
ANYCRAWL_SCHEDULED_TASKS_LIMIT_ENABLED=false
ANYCRAWL_SCHEDULED_TASKS_LIMIT_FREE=1
ANYCRAWL_SCHEDULED_TASKS_LIMIT_PAID=100

ANYCRAWL_WEBHOOKS_ENABLED=true
ANYCRAWL_WEBHOOKS_QUEUE_CONCURRENCY=10
ALLOW_LOCAL_WEBHOOKS=false  # Set to true only for testing
